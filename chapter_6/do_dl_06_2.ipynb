{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Temp\\ipykernel_14124\\4031633957.py:1: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "from imp import reload\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import d2l_pytorch.d2l as d2l\n",
    "\n",
    "reload(d2l)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics(\n",
    "  \"F:\\python_code\\DL\\Datasets\\JayChouLyrics\\jaychou_lyrics.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, n_class, dtype=torch.float32):\n",
    "  x = x.long()\n",
    "  res = torch.zeros(x.shape[0], n_class, dtype=dtype, device=x.device)\n",
    "  res.scatter_(1, x.view(-1, 1), 1)\n",
    "  return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0, 2])\n",
    "x.long()\n",
    "# one_hot(x, vocab_size)\n",
    "F.one_hot(x, vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1028])\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(10).view(2, 5)\n",
    "inputs = d2l.to_onehot(X, vocab_size)\n",
    "print(len(inputs), inputs[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use cuda\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型参数\n",
    "num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\n",
    "print(\"will use\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params():\n",
    "  def _one(shape):\n",
    "    ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)\n",
    "    return torch.nn.Parameter(ts, requires_grad=True)\n",
    "\n",
    "  W_xh = _one((num_inputs, num_hiddens))\n",
    "  W_hh = _one((num_hiddens, num_hiddens))\n",
    "  b_h = torch.nn.Parameter(torch.zeros(num_hiddens, device=device, requires_grad=True))\n",
    "  W_hq = _one((num_hiddens, num_outputs))\n",
    "  b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, requires_grad=True))\n",
    "  return nn.ParameterList([W_xh, W_hh, b_h, W_hq, b_q])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "def init_rnn_state(batch_size, num_hiddens, device):\n",
    "  return (torch.zeros((batch_size, num_hiddens), device=device),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "  W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "  (H,) = state\n",
    "  outputs = []\n",
    "  for X in inputs:\n",
    "    H = torch.tanh(torch.matmul(X, W_xh) + torch.matmul(H, W_hh) + b_h)\n",
    "    Y = torch.matmul(H, W_hq) + b_q\n",
    "    outputs.append(Y)\n",
    "\n",
    "  return outputs, (H,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1028]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "from d2l_pytorch.d2l import to_onehot\n",
    "\n",
    "\n",
    "state = init_rnn_state(X.shape[0], num_hiddens, device)\n",
    "inputs = to_onehot(X.to(device), vocab_size)\n",
    "params = get_params()\n",
    "outputs, state_new = rnn(inputs, state, params)\n",
    "print(len(outputs), outputs[0].shape, state_new[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义预测函数\n",
    "def predict_rnn(\n",
    "  prefix,\n",
    "  num_chars,\n",
    "  rnn,\n",
    "  params,\n",
    "  init_rnn_state,\n",
    "  num_hiddens,\n",
    "  vocab_size,\n",
    "  device,\n",
    "  idx_to_char,\n",
    "  char_to_idx,\n",
    "):\n",
    "  state = init_rnn_state(1, num_hiddens, device)\n",
    "  output = [char_to_idx[prefix[0]]]\n",
    "\n",
    "  for t in range(num_chars + len(prefix) - 1):\n",
    "    X = to_onehot(torch.tensor([[output[-1]]], device=device), vocab_size)\n",
    "    (Y, state) = rnn(X, state, params)\n",
    "\n",
    "    if t < len(prefix) - 1:\n",
    "      output.append(char_to_idx[prefix[t + 1]])\n",
    "    else:\n",
    "      output.append(int(Y[0].argmax(dim=1).item()))\n",
    "\n",
    "  return \"\".join([idx_to_char[i] for i in output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开书年解败赏休及为旁辈'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rnn(\n",
    "  \"分开\", 10, rnn, params, init_rnn_state, num_hiddens, vocab_size, device, idx_to_char, char_to_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(params, theta, device):\n",
    "  norm = torch.tensor([0.0], device=device)\n",
    "  for param in params:\n",
    "    norm += (param.grad.data**2).sum()\n",
    "\n",
    "  norm = norm.sqrt().item()\n",
    "  if norm > theta:\n",
    "    for param in params:\n",
    "      param.grad.data *= theta / norm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU 网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'd2l_pytorch.d2l' from '..\\\\d2l_pytorch\\\\d2l.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from imp import reload\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import d2l_pytorch.d2l as d2l\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "reload(d2l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics(\"F:\\python_code\\DL\\Datasets\\JayChouLyrics\\jaychou_lyrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use cuda\n"
     ]
    }
   ],
   "source": [
    "num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\n",
    "print(\"will use\", device)\n",
    "\n",
    "def get_params():\n",
    "  def _one(shape):\n",
    "    ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype = torch.float32)\n",
    "    return torch.nn.Parameter(ts, requires_grad=True)\n",
    "  def _three():\n",
    "    return (_one((num_inputs, num_hiddens)), _one((num_hiddens, num_hiddens)), torch.nn.Parameter(torch.zeros(num_hiddens, device=device, dtype=torch.float32), requires_grad=True))\n",
    "  \n",
    "  W_xz, W_hz, b_z = _three()\n",
    "  W_xr, W_hr, b_r = _three()\n",
    "  W_xh, W_hh, b_h = _three()\n",
    "\n",
    "  W_hq = _one((num_hiddens, num_outputs))\n",
    "  b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, dtype=torch.float32),requires_grad=True)\n",
    "  return nn.ParameterList([W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_gru_state(batch_size, num_hiddens, device):\n",
    "  return (torch.zeros((batch_size, num_hiddens), device=device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(inputs, state, params):\n",
    "  W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "  (H,) = state\n",
    "  outputs = []\n",
    "\n",
    "  for X in inputs:\n",
    "    Z = torch.sigmoid(torch.matmul(X, W_xz) + torch.matmul(H, W_hz) + b_z)\n",
    "    R = torch.sigmoid(torch.matmul(X, W_xr) + torch.matmul(H, W_hr) + b_r)\n",
    "    H_tilda = torch.tanh(torch.matmul(X, W_xh) + torch.matmul(R * H, W_hh) + b_h)\n",
    "    H = Z * H + (1 - Z) * H_tilda\n",
    "    Y = torch.matmul(H, W_hq) + b_q\n",
    "    outputs.append(Y)\n",
    "  return outputs, (H,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, perplexity 143.895503, time 0.92 sec\n",
      " - 分开\n",
      "我想你你 我不了\n",
      "我想你你你\n",
      "我想你你不了\n",
      "我想你你你\n",
      "我想你你不了\n",
      "我想你你你\n",
      "我想你你不了\n",
      "我\n",
      " - 不分开\n",
      "我想你你 我不了\n",
      "我想你你你\n",
      "我想你你不了\n",
      "我想你你你\n",
      "我想你你不了\n",
      "我想你你你\n",
      "我想你你不了\n",
      "我\n",
      "epoch 80, perplexity 27.395228, time 0.96 sec\n",
      " - 分开\n",
      "我想要这样\n",
      "我该好好生活\n",
      "我该好好生活\n",
      "我该好好生活\n",
      "我该好好生活\n",
      "我该好好生活\n",
      "我该好好生活\n",
      "我\n",
      " - 不分开\n",
      "我想要这样\n",
      "我该好好生活\n",
      "我该好好生活\n",
      "我该好好生活\n",
      "我该好好生活\n",
      "我该好好生活\n",
      "我该好好生活\n",
      "我\n",
      "epoch 120, perplexity 4.958879, time 0.92 sec\n",
      " - 分开的模丽\n",
      "让我说你的爱写在西元前\n",
      "深埋在美索不达米亚平原\n",
      "用楔形文字我妈下难发\n",
      "我爱上的话写有西元前\n",
      "\n",
      " - 不分开\n",
      "爱是不觉 你来一碗热留\n",
      "你这在黑秋 静静悔够不留\n",
      "景色入烛 温暖了空屋\n",
      "白色蜡烛 温暖了空屋\n",
      "白色\n",
      "epoch 160, perplexity 1.653393, time 1.08 sec\n",
      " - 分开\n",
      "让我心到你\n",
      "就样去一个人\n",
      "后知回觉\n",
      "后知后觉不离\n",
      "我该好好生活\n",
      "静静悄悄默默离开\n",
      "陷入了危险边缘B\n",
      " - 不分开\n",
      "其是我怕开痛痛\n",
      "像像样童话 我有没直 \n",
      "没有你烦我有多烦熬多\n",
      "爸没有你的我有多\n",
      "家散 没爱简久了吧\n"
     ]
    }
   ],
   "source": [
    "num_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2\n",
    "pred_period, pred_len, prefixes = 40, 50, [\"分开\", \"不分开\"]\n",
    "\n",
    "d2l.train_and_predict_rnn(\n",
    "  gru,\n",
    "  get_params,\n",
    "  init_gru_state,\n",
    "  num_hiddens,\n",
    "  vocab_size,\n",
    "  device,\n",
    "  corpus_indices,\n",
    "  idx_to_char,\n",
    "  char_to_idx,\n",
    "  False,\n",
    "  num_epochs,\n",
    "  num_steps,\n",
    "  lr,\n",
    "  clipping_theta,\n",
    "  batch_size,\n",
    "  pred_period,\n",
    "  pred_len,\n",
    "  prefixes,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 40, perplexity 1.031442 , time 0.13 sec \n",
      " - 分开始打呼\n",
      "管家是一只会说法语举止优雅的猪\n",
      "吸血前会念约翰福音做为弥补\n",
      "拥有一双蓝色眼睛的凯萨琳公主\n",
      "专\n",
      " - 不分开不了口让她知道\n",
      "就是那么简单几句 我办不到\n",
      "整颗心悬在半空\n",
      "我只能够远远看著\n",
      "这些我都做得到\n",
      "但那个\n",
      " epoch 80, perplexity 1.045292 , time 0.13 sec \n",
      " - 分开的玩笑\n",
      "想通 却又再考倒我\n",
      "说散 你想很久了吧?\n",
      "败给你的黑色幽默\n",
      "说散 你想很久了吧?\n",
      "我的认真败\n",
      " - 不分开暴风圈来不及逃\n",
      "我不能再想\n",
      "我不能再想\n",
      "我不 我不 我不能\n",
      "爱情走的太快就像龙卷风\n",
      "离不开暴风圈来不\n",
      " epoch 120, perplexity 1.014025 , time 0.14 sec \n",
      " - 分开的玩笑\n",
      "想通 却又再考倒我\n",
      "说散 你想很久了吧?\n",
      "败给你的黑色幽默\n",
      "说散 你想很久了吧?\n",
      "我的认真败\n",
      " - 不分开不了口让她知道\n",
      "就是那么简单几句 我办不到\n",
      "整颗心悬在半空\n",
      "我只能够远远看著\n",
      "这些我都做得到\n",
      "但那个\n",
      " epoch 160, perplexity 1.535654 , time 0.13 sec \n",
      " - 分开现迷了路上\n",
      "你的脑袋有问题\n",
      "随便说说\n",
      "是那句抱歉 在感动 谁让它比谁下午\n",
      "手牵手\n",
      "一步两步三步四步望\n",
      " - 不分开我爱你想想你想想你想很久了吧?\n",
      "想通 却又再考倒我\n",
      "说散 你想很久了吧?\n",
      "败给黑色幽默\n",
      "走过了很多地\n"
     ]
    }
   ],
   "source": [
    "# 简洁实现使用nn中的GRU类\n",
    "lr = 1e-2\n",
    "gru_layer = nn.GRU(input_size=vocab_size, hidden_size=num_hiddens)\n",
    "model = d2l.RNNModel(gru_layer, vocab_size).to(device)\n",
    "\n",
    "d2l.train_and_predict_rnn_pytorch(\n",
    "  model,\n",
    "  num_hiddens,\n",
    "  vocab_size,\n",
    "  device,\n",
    "  corpus_indices,\n",
    "  idx_to_char,\n",
    "  char_to_idx,\n",
    "  num_epochs,\n",
    "  num_steps,\n",
    "  lr,\n",
    "  clipping_theta,\n",
    "  batch_size,\n",
    "  pred_period,\n",
    "  pred_len,\n",
    "  prefixes,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
